{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File D:\\Data\\Kaggle_Titanic_Train.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2f029a24b395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# read training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtitanic_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:\\Data\\Kaggle_Titanic_Train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# extract title from Name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    472\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3173)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:5912)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File D:\\Data\\Kaggle_Titanic_Train.csv does not exist"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# read training data \n",
    "titanic_train = pd.read_csv('D:\\Data\\Kaggle_Titanic_Train.csv')\n",
    "\n",
    "# extract title from Name\n",
    "df_titles = titanic_train\n",
    "df_titles['NameComma'] = df_titles.Name.apply(lambda x: x.split(',')[1])\n",
    "df_titles['LastName'] = df_titles.Name.apply(lambda x: x.split(',')[0])\n",
    "df_titles['Title'] = df_titles.NameComma.apply(lambda x: x.split('.')[0])\n",
    "df_titles['Title'] = df_titles['Title'].map(lambda x: x.lstrip())\n",
    "\n",
    "# fill 2 missing values with most common 'S'\n",
    "df_titles.Embarked.fillna('S', inplace=True)\n",
    "\n",
    "# create dummy variables for title, embarked, pclass(for more than two categrey)\n",
    "title_dummies = pd.get_dummies(df_titles['Title'])\n",
    "title_dummies = title_dummies[['Master','Miss','Mr','Mrs']]\n",
    "pclass_dummies = pd.get_dummies(df_titles['Pclass'])\n",
    "pclass_dummies.columns = ['Pclass1','Pclass2','Pclass3']\n",
    "pclass_dummies = pclass_dummies[['Pclass1','Pclass3']]\n",
    "embarked_dummies = pd.get_dummies(df_titles['Embarked'])\n",
    "embarked_dummies = embarked_dummies[['C','S']]\n",
    "dummies = pd.concat([title_dummies,pclass_dummies,embarked_dummies], axis = 1)\n",
    "\n",
    "# binary for sex, cabin \n",
    "def gender(df):\n",
    "    if df['Sex'] == 'female':\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "def cabin(df):\n",
    "    if pd.isnull(df['Cabin']) == True:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "df_titles['Sex'] = df_titles.apply(gender,axis=1)\n",
    "df_titles['Cabin'] = df_titles.apply(cabin,axis=1)\n",
    "\n",
    "# merge dummies with original data\n",
    "df_with_dummies = pd.concat([df_titles,dummies],axis=1)\n",
    "\n",
    "# drop unnecessary vars\n",
    "prep_data = df_with_dummies.drop(['Embarked','Pclass','Name','Ticket',\n",
    "                                            'NameComma','LastName','Title'], axis=1)\n",
    "\n",
    "# prep for age model, drop missing ages\n",
    "age_predict_ready = df_with_dummies.dropna()\n",
    "age_predict_ready = age_predict_ready.drop(['PassengerId','Embarked','Pclass','Survived','Name','Ticket',\n",
    "                                            'NameComma','LastName','Title'], axis=1)\n",
    "# develop age model\n",
    "Y_age = age_predict_ready.Age\n",
    "X_age = age_predict_ready.drop(['Age'],axis=1)\n",
    "\n",
    "Y_age = np.ravel(Y_age)\n",
    "\n",
    "age_lin_model = LinearRegression()\n",
    "age_lin_model.fit(X_age,Y_age)\n",
    "age_lin_model.score(X_age,Y_age)      \n",
    "\n",
    "# create df with missing ages \n",
    "missing_age = df_with_dummies\n",
    "missing_age = missing_age[missing_age['Age'].apply(np.isnan)]\n",
    "missing_age = missing_age.drop(['Age','Embarked','Pclass','Survived','Name','Ticket',\n",
    "                                            'NameComma','LastName','Title'], axis=1)\n",
    "\n",
    "missing_age_ready = missing_age.drop(['PassengerId'],axis=1)\n",
    "\n",
    "# apply age model to missing ages\n",
    "missing_age_pred = pd.DataFrame(age_lin_model.predict(missing_age_ready))\n",
    "missing_age_pred.columns = ['AgePred']\n",
    "\n",
    "# set index to concat data\n",
    "missing_age.index = range(177)\n",
    "\n",
    "passid_agepred = pd.concat([missing_age,missing_age_pred],axis=1)[['PassengerId','AgePred']]\n",
    "\n",
    "# merge predictions with original data\n",
    "agepred_titanic_train = pd.merge(prep_data,passid_agepred,on='PassengerId',how='outer')\n",
    "\n",
    "# replace missing data with predictions\n",
    "def combine_age(df):\n",
    "    if pd.isnull(df['Age']) == True:\n",
    "        return df['AgePred']\n",
    "    else:\n",
    "        return df['Age']\n",
    "\n",
    "agepred_titanic_train['Age'] = agepred_titanic_train.apply(combine_age,axis=1)\n",
    "\n",
    "# prep for log model\n",
    "agepred_titanic_train = agepred_titanic_train.drop(['PassengerId','AgePred'],axis=1)\n",
    "\n",
    "# create log model for survival\n",
    "Y_surv = np.ravel(agepred_titanic_train.Survived)\n",
    "X_surv = agepred_titanic_train.drop(['Survived'],axis=1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X_surv,Y_surv)\n",
    "log_model.score(X_surv,Y_surv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read test data\n",
    "titanic_test = pd.read_csv('D:\\Data\\Kaggle_Titanic_Test.csv')\n",
    "\n",
    "# replace missing fare with mean - change to median to accomodate skewed data\n",
    "tt = titanic_test\n",
    "tt.Fare.fillna(tt.Fare.dropna().mean(), inplace=True)\n",
    "\n",
    "# extract title from name\n",
    "tt['NameComma'] = tt.Name.apply(lambda x: x.split(',')[1])\n",
    "tt['LastName'] = tt.Name.apply(lambda x: x.split(',')[0])\n",
    "tt['Title'] = tt.NameComma.apply(lambda x: x.split('.')[0])\n",
    "tt['Title'] = tt['Title'].map(lambda x: x.lstrip())\n",
    "\n",
    "# create dummy vars for title, embarked, pclass\n",
    "title_dummies2 = pd.get_dummies(tt['Title'])\n",
    "title_dummies2 = title_dummies2[['Master','Miss','Mr','Mrs']]\n",
    "pclass_dummies2 = pd.get_dummies(tt['Pclass'])\n",
    "pclass_dummies2.columns = ['Pclass1','Pclass2','Pclass3']\n",
    "pclass_dummies2 = pclass_dummies2[['Pclass1','Pclass3']]\n",
    "embarked_dummies2 = pd.get_dummies(tt['Embarked'])\n",
    "embarked_dummies2 = embarked_dummies2[['C','S']]\n",
    "dummies2 = pd.concat([title_dummies2,pclass_dummies2,embarked_dummies2], axis = 1)\n",
    "\n",
    "# binary for sex and cabin\n",
    "def gender(df):\n",
    "    if df['Sex'] == 'female':\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "def cabin(df):\n",
    "    if pd.isnull(df['Cabin']) == True:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "tt['Sex'] = tt.apply(gender,axis=1)\n",
    "tt['Cabin'] = tt.apply(cabin,axis=1)\n",
    "\n",
    "# combine dummies with original data\n",
    "df_with_dummies2 = pd.concat([tt,dummies2],axis=1)\n",
    "\n",
    "# drop unnecessary vars \n",
    "prep_data2 = df_with_dummies2.drop(['Embarked','Pclass','Name','Ticket',\n",
    "                                            'NameComma','LastName','Title'], axis=1)\n",
    "# separate missing age df and prep for age model\n",
    "missing_age2 = df_with_dummies2\n",
    "missing_age2 = missing_age2[missing_age2['Age'].apply(np.isnan)]\n",
    "missing_age2 = missing_age2.drop(['Age','Embarked','Pclass','Name','Ticket',\n",
    "                                            'NameComma','LastName','Title'], axis=1)\n",
    "missing_age2.index = range(86)\n",
    "\n",
    "missing_age_ready2 = missing_age2.drop(['PassengerId'],axis=1)\n",
    "\n",
    "# apply age model \n",
    "missing_age_pred2 = pd.DataFrame(age_lin_model.predict(missing_age_ready2))\n",
    "\n",
    "missing_age_pred2.columns = ['AgePred2']\n",
    "\n",
    "# combine age predictions with original data\n",
    "passid_agepred2 = pd.concat([missing_age2,missing_age_pred2],axis=1)[['PassengerId','AgePred2']]\n",
    "\n",
    "agepred_titanic_test = pd.merge(prep_data2,passid_agepred2,on='PassengerId',how='outer')\n",
    "\n",
    "# replace missing age with age prediction\n",
    "def combine_age(df):\n",
    "    if pd.isnull(df['Age']) == True:\n",
    "        return df['AgePred2']\n",
    "    else:\n",
    "        return df['Age']\n",
    "\n",
    "agepred_titanic_test['Age'] = agepred_titanic_test.apply(combine_age,axis=1)\n",
    "agepred_titanic_test_ready = agepred_titanic_test.drop(['PassengerId','AgePred2'],axis=1)\n",
    "\n",
    "# apply log model to test data. prep for submission\n",
    "surv_pred = pd.DataFrame(log_model.predict(agepred_titanic_test_ready))\n",
    "surv_pred.columns = ['Survived']\n",
    "surv_pred['Survived'] = surv_pred['Survived'].astype(int)\n",
    "\n",
    "results = pd.DataFrame(zip(agepred_titanic_test.PassengerId,surv_pred.Survived))\n",
    "results.columns = ['PassengerId','Survived']\n",
    "\n",
    "results.to_csv('D:\\Data\\Kaggle_Titanic_Prediction_LinAge.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
